# -*- coding: utf-8 -*-
"""Untitled13.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Zeen3hea7wb56cJbmpasM6fq54zGGKoH
"""

#!/usr/bin/env python3
"""


Advanced Time Series Forecasting with Deep Learning and Explainability
- Generates synthetic multivariate time series (5 features, 3000+ rows)
- Preprocesses and creates sliding windows
- Baseline: SARIMAX
- Deep models: LSTM and Transformer
- Hyperparameter search (simple grid loop)
- Metrics: RMSE, MAE, MAPE
- Explainability: SHAP for LSTM; Attention weights visualization for Transformer

Requires:
    numpy, pandas, matplotlib, sklearn, tensorflow, statsmodels, shap, seaborn
"""

import os
import math
import random
import tempfile
from typing import Tuple, Dict, Any

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

import statsmodels.api as sm

# Try importing shap; handle gracefully if missing
try:
    import shap
    SHAP_AVAILABLE = True
except Exception:
    SHAP_AVAILABLE = False

# ---------------------------
# Utilities: metrics, plotting
# ---------------------------
def rmse(y_true: np.ndarray, y_pred: np.ndarray) -> float:
    return float(np.sqrt(np.mean((y_true - y_pred) ** 2)))


def mae(y_true: np.ndarray, y_pred: np.ndarray) -> float:
    return float(np.mean(np.abs(y_true - y_pred)))


def mape(y_true: np.ndarray, y_pred: np.ndarray) -> float:
    # avoid division by zero
    denom = np.where(np.abs(y_true) < 1e-8, 1e-8, np.abs(y_true))
    return float(np.mean(np.abs((y_true - y_pred) / denom)) * 100.0)


def plot_series(df: pd.DataFrame, cols: list, title: str = "Series plot"):
    plt.figure(figsize=(12, 5))
    for c in cols:
        plt.plot(df.index, df[c], label=c)
    plt.legend()
    plt.title(title)
    plt.tight_layout()
    plt.show()


# ---------------------------
# Data generation & processing
# ---------------------------
def generate_synthetic_multivariate(
    n_rows: int = 3000, n_features: int = 6, seed: int = 42
) -> pd.DataFrame:
    """
    Generate a synthetic multivariate time series dataset.
    - One main target (col 'y') and (n_features-1) covariates.
    - Includes seasonality, trend, and noise.
    """
    rng = np.random.default_rng(seed)
    time = np.arange(n_rows)
    df = pd.DataFrame(index=pd.date_range("2000-01-01", periods=n_rows, freq="H"))

    # Target: composed of trend, seasonality, and noise
    trend = 0.0005 * time  # slow trend
    seasonal1 = 2.0 * np.sin(2 * np.pi * time / 24)  # daily seasonality
    seasonal2 = 0.5 * np.sin(2 * np.pi * time / (24 * 7))  # weekly
    noise = rng.normal(scale=0.5, size=n_rows)

    base = 10 + trend + seasonal1 + seasonal2 + noise
    df["y"] = base

    # Covariates correlated with y
    for i in range(1, n_features):
        coeff = rng.normal(loc=0.5, scale=0.2)
        seasonal = coeff * np.sin(2 * np.pi * time / (12 + i))
        noise_i = rng.normal(scale=0.8, size=n_rows)
        df[f"x{i}"] = coeff * base + seasonal + noise_i

    return df


def create_sequences(
    data: np.ndarray, seq_len: int, pred_horizon: int = 1
) -> Tuple[np.ndarray, np.ndarray]:
    """
    Create sliding window sequences for supervised learning.
    data: shape (n_samples, n_features)
    returns X shape (n_windows, seq_len, n_features), y shape (n_windows, pred_horizon)
    """
    X, y = [], []
    n_samples = data.shape[0]
    for start in range(n_samples - seq_len - pred_horizon + 1):
        end = start + seq_len
        X.append(data[start:end])
        y.append(data[end:end + pred_horizon, 0])  # target is column 0 (y)
    return np.array(X), np.array(y)


# ---------------------------
# Baseline: SARIMAX
# ---------------------------
def train_sarimax_baseline(df: pd.DataFrame, train_end: int, test_len: int = 200) -> Dict:
    """
    Fit a SARIMAX baseline on the target using last `test_len` points for test.
    train_end: index position marking the end of training data (exclusive)
    """
    y = df["y"]
    exog = df.drop(columns=["y"])

    y_train = y.iloc[:train_end]
    exog_train = exog.iloc[:train_end]
    y_test = y.iloc[train_end:train_end + test_len]
    exog_test = exog.iloc[train_end:train_end + test_len]

    # Simple SARIMAX(p,d,q)(P,D,Q,s) - keep small to run fast
    order = (1, 0, 1)
    seasonal_order = (1, 0, 1, 24)  # daily seasonality for hourly data

    print("Training SARIMAX baseline... (this may take a moment)")
    model = sm.tsa.statespace.SARIMAX(
        endog=y_train,
        exog=exog_train,
        order=order,
        seasonal_order=seasonal_order,
        enforce_stationarity=False,
        enforce_invertibility=False,
    )
    res = model.fit(disp=False)

    pred = res.predict(start=train_end, end=train_end + test_len - 1, exog=exog_test)
    metrics = {
        "rmse": rmse(y_test.values, pred.values),
        "mae": mae(y_test.values, pred.values),
        "mape": mape(y_test.values, pred.values),
    }
    print("SARIMAX metrics:", metrics)
    return {"model": res, "pred": pred, "y_test": y_test, "metrics": metrics}


# ---------------------------
# Deep learning models
# ---------------------------
def build_lstm(
    input_shape: Tuple[int, int],
    hidden_units: int = 64,
    dropout: float = 0.1,
    lr: float = 1e-3,
) -> keras.Model:
    inputs = keras.Input(shape=input_shape, name="lstm_input")
    x = layers.Masking()(inputs)
    x = layers.LSTM(hidden_units, return_sequences=False)(x)
    x = layers.Dropout(dropout)(x)
    outputs = layers.Dense(1, activation="linear", name="y_out")(x)
    model = keras.Model(inputs=inputs, outputs=outputs, name="LSTM_forecaster")
    model.compile(optimizer=keras.optimizers.Adam(lr), loss="mse")
    return model


# Simple Transformer block components
def positional_encoding(seq_len: int, d_model: int) -> np.ndarray:
    """Return positional encoding of shape (1, seq_len, d_model)."""
    pos = np.arange(seq_len)[:, np.newaxis]
    i = np.arange(d_model)[np.newaxis, :]
    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))
    angle_rads = pos * angle_rates
    pe = np.zeros((seq_len, d_model))
    pe[:, 0::2] = np.sin(angle_rads[:, 0::2])
    pe[:, 1::2] = np.cos(angle_rads[:, 1::2])
    return pe[np.newaxis, ...]


class SimpleTransformerBlock(layers.Layer):
    def __init__(self, d_model: int, num_heads: int, ff_dim: int, rate: float = 0.1):
        super().__init__()
        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)
        self.ffn = keras.Sequential(
            [layers.Dense(ff_dim, activation="relu"), layers.Dense(d_model)]
        )
        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)
        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)
        self.dropout1 = layers.Dropout(rate)
        self.dropout2 = layers.Dropout(rate)

    def call(self, inputs, training=False, mask=None):
        attn_output = self.att(inputs, inputs, attention_mask=mask)
        attn_output = self.dropout1(attn_output, training=training)
        out1 = self.layernorm1(inputs + attn_output)
        ffn_output = self.ffn(out1)
        ffn_output = self.dropout2(ffn_output, training=training)
        return self.layernorm2(out1 + ffn_output)


def build_transformer(
    input_shape: Tuple[int, int],
    d_model: int = 64,
    num_heads: int = 4,
    ff_dim: int = 64,
    num_blocks: int = 2,
    lr: float = 1e-3,
) -> keras.Model:
    seq_len, n_features = input_shape
    inputs = keras.Input(shape=(seq_len, n_features), name="transformer_input")

    # Project features to d_model dims
    proj = layers.Dense(d_model)(inputs)
    # Add positional encoding
    pos_enc = positional_encoding(seq_len, d_model)
    x = proj + tf.cast(pos_enc, tf.float32)

    # Transformer blocks
    for _ in range(num_blocks):
        x = SimpleTransformerBlock(d_model, num_heads, ff_dim)(x)

    # Pooling across time then Dense for output
    x = layers.GlobalAveragePooling1D()(x)
    outputs = layers.Dense(1, activation="linear")(x)

    model = keras.Model(inputs=inputs, outputs=outputs, name="Transformer_forecaster")
    model.compile(optimizer=keras.optimizers.Adam(lr), loss="mse")
    return model


# Extract attention weights helper (requires modification to MultiHeadAttention call to return weights)
# In TF 2.11+, MultiHeadAttention supports return_attention_scores=True in call, but here we used the default.
# To capture attention, we can create a separate MultiHeadAttention layer and call it manually with return_attention_scores=True.
def build_transformer_with_attention_logging(
    input_shape: Tuple[int, int],
    d_model: int = 64,
    num_heads: int = 4,
    ff_dim: int = 64,
    num_blocks: int = 2,
    lr: float = 1e-3,
):
    """
    Returns (model, attention_layers_list)
    attention_layers_list can be used to inspect attention scores by calling them manually.
    """
    seq_len, n_features = input_shape
    inputs = keras.Input(shape=(seq_len, n_features), name="transformer_input")

    proj = layers.Dense(d_model)(inputs)
    pos_enc = positional_encoding(seq_len, d_model)
    x = proj + tf.cast(pos_enc, tf.float32)

    attention_layers = []
    for _ in range(num_blocks):
        # Create a MultiHeadAttention layer that we can call with return_attention_scores=True
        att_layer = layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model, output_shape=d_model)
        attention_layers.append(att_layer)
        att_out, att_scores = att_layer(x, x, return_attention_scores=True)
        att_out = layers.Dropout(0.1)(att_out)
        x = layers.LayerNormalization(epsilon=1e-6)(x + att_out)
        ffn = keras.Sequential([layers.Dense(ff_dim, activation="relu"), layers.Dense(d_model)])
        ffn_out = ffn(x)
        ffn_out = layers.Dropout(0.1)(ffn_out)
        x = layers.LayerNormalization(epsilon=1e-6)(x + ffn_out)

    x = layers.GlobalAveragePooling1D()(x)
    outputs = layers.Dense(1, activation="linear")(x)

    model = keras.Model(inputs=inputs, outputs=outputs, name="Transformer_with_attention")
    model.compile(optimizer=keras.optimizers.Adam(lr), loss="mse")
    return model, attention_layers


# ---------------------------
# Training and evaluation
# ---------------------------
def simple_grid_search_and_train(
    X_train: np.ndarray,
    y_train: np.ndarray,
    X_val: np.ndarray,
    y_val: np.ndarray,
    model_type: str = "lstm",
    search_space: Dict[str, list] = None,
    epochs: int = 20,
    batch_size: int = 64,
    verbose: int = 0,
) -> Dict[str, Any]:
    """
    Search over small grid and return best model and history.
    model_type: 'lstm' or 'transformer'
    """
    if search_space is None:
        search_space = {
            "seq_len": [X_train.shape[1]],
            "hidden_units": [32, 64],
            "lr": [1e-3],
        }
    best_rmse = float("inf")
    best_result = None

    for hidden in search_space.get("hidden_units", [64]):
        for lr in search_space.get("lr", [1e-3]):
            # NOTE: seq_len is baked into X_train shape already
            if model_type == "lstm":
                model = build_lstm(input_shape=(X_train.shape[1], X_train.shape[2]), hidden_units=hidden, lr=lr)
            else:
                model = build_transformer(input_shape=(X_train.shape[1], X_train.shape[2]), d_model=hidden, lr=lr)

            es = keras.callbacks.EarlyStopping(monitor="val_loss", patience=5, restore_best_weights=True)
            history = model.fit(
                X_train, y_train,
                validation_data=(X_val, y_val),
                epochs=epochs,
                batch_size=batch_size,
                callbacks=[es],
                verbose=verbose
            )
            preds_val = model.predict(X_val).ravel()
            val_rmse = rmse(y_val.ravel(), preds_val)
            print(f"Model {model_type} hidden={hidden} lr={lr} val_rmse={val_rmse:.4f}")

            if val_rmse < best_rmse:
                best_rmse = val_rmse
                best_result = {
                    "model": model,
                    "history": history,
                    "val_rmse": val_rmse,
                    "hidden": hidden,
                    "lr": lr,
                }
    return best_result


# ---------------------------
# Explainability
# ---------------------------
def explain_lstm_with_shap(model: keras.Model, X_sample: np.ndarray, feature_names: list):
    if not SHAP_AVAILABLE:
        print("SHAP not available. Skipping SHAP explanations. Install shap to enable.")
        return
    # For Keras models, use DeepExplainer (works with TF models reasonably)
    # We will use a small background sample
    bg = X_sample[np.random.choice(len(X_sample), size=min(100, len(X_sample)), replace=False)]
    explainer = shap.DeepExplainer(model, bg)
    shap_values = explainer.shap_values(X_sample[:200])  # shape: [1][200, seq_len, n_features]
    # shap_values[0] -> array of shape (200, seq_len, n_features)
    # Sum across time to get feature importance
    shap_sum = np.mean(np.abs(shap_values[0]), axis=0)  # (seq_len, n_features)
    mean_over_time = np.mean(shap_sum, axis=0)  # (n_features,)
    df_imp = pd.DataFrame({"feature": feature_names, "mean_abs_shap": mean_over_time})
    df_imp = df_imp.sort_values("mean_abs_shap", ascending=False)
    print("Top features by mean |SHAP|:", df_imp.head())
    # Plot
    plt.figure(figsize=(8, 4))
    sns.barplot(x="mean_abs_shap", y="feature", data=df_imp)
    plt.title("LSTM SHAP feature importance (summed over time)")
    plt.tight_layout()
    plt.show()
    return df_imp, shap_values


def plot_transformer_attention(model: keras.Model, X_sample: np.ndarray, layer_idx: int = 0):
    """
    If model was built using layers.MultiHeadAttention and returns attention_scores, you could extract them.
    In this script we built a transformer without returning attention directly; advanced extraction requires
    custom attention layers or re-calling those layers with return_attention_scores=True.

    Here we'll re-create a single MultiHeadAttention and call it to get attention for a sample pair
    using inputs projected similarly to the model's first Dense projection.
    """
    # Warning: this is an approximation â€” attention weights from the trained MHA inside the model
    # are not directly retrieved here unless you wired them into the model outputs.
    try:
        # Try to find the first Dense projection layer weights to emulate projection
        dense_proj = None
        for layer in model.layers:
            if isinstance(layer, layers.Dense):
                dense_proj = layer
                break
        seq_len = X_sample.shape[1]
        # Create a MultiHeadAttention layer with same config used in build_transformer
        mha = layers.MultiHeadAttention(num_heads=4, key_dim=64)
        # Project input using the dense layer we found if shapes align; otherwise use identity
        projected = X_sample
        if dense_proj is not None and dense_proj.input_shape[-1] == X_sample.shape[-1]:
            # apply the dense projection weights manually
            projected = dense_proj(X_sample)
        # Call with return_attention_scores True if available
        try:
            attn_out, attn_scores = mha(projected, projected, return_attention_scores=True)
        except TypeError:
            # Older TF version may not support return_attention_scores
            attn_out = mha(projected, projected)
            attn_scores = None

        if attn_scores is None:
            print("Could not retrieve attention scores directly from MHA in this TF version.")
            return None

        # attn_scores shape: (batch, num_heads, query_len, key_len)
        avg_scores = np.mean(attn_scores, axis=1)  # average across heads -> (batch, qlen, klen)
        avg_for_sample = avg_scores[0]  # first sample
        plt.figure(figsize=(6, 5))
        sns.heatmap(avg_for_sample, cmap="viridis")
        plt.title("Average attention scores (query_pos x key_pos) for sample 0")
        plt.xlabel("Key position")
        plt.ylabel("Query position")
        plt.tight_layout()
        plt.show()
        return avg_for_sample
    except Exception as e:
        print("Attention plotting failed:", e)
        return None


# ---------------------------
# Main pipeline
# ---------------------------
def main():
    # Configuration
    RANDOM_SEED = 42
    np.random.seed(RANDOM_SEED)
    tf.random.set_seed(RANDOM_SEED)
    random.seed(RANDOM_SEED)

    # 1) Generate synthetic dataset
    df = generate_synthetic_multivariate(n_rows=3500, n_features=6, seed=RANDOM_SEED)
    print("Generated data sample:")
    print(df.head())

    # Plot a few series
    plot_series(df, ["y", "x1", "x2"], title="Target and two covariates (first view)")

    # 2) Preprocess: train/val/test split & scaling
    test_len = 500
    val_len = 500
    total = len(df)
    train_end = total - (val_len + test_len)

    df_train = df.iloc[:train_end]
    df_val = df.iloc[train_end:train_end + val_len]
    df_test = df.iloc[train_end + val_len:train_end + val_len + test_len]

    scaler = StandardScaler()
    scaler.fit(df_train.values)
    df_scaled = pd.DataFrame(scaler.transform(df.values), index=df.index, columns=df.columns)

    # 3) Sequence generation
    seq_len = 48  # example: use the last 48 hours to predict next hour
    pred_horizon = 1
    X, y = create_sequences(df_scaled.values, seq_len=seq_len, pred_horizon=pred_horizon)
    # Split into train/val/test
    n_train = len(df_train) - seq_len - pred_horizon + 1
    n_val = len(df_val)

    X_train = X[:n_train]
    y_train = y[:n_train]
    X_val = X[n_train:n_train + n_val]
    y_val = y[n_train:n_train + n_val]
    X_test = X[n_train + n_val:]
    y_test = y[n_train + n_val:]

    print("Shapes:", X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape)

    # 4) Baseline SARIMAX
    sarimax_res = train_sarimax_baseline(df, train_end=train_end, test_len=test_len)

    # 5) Train LSTM with simple grid search
    lstm_search_space = {"hidden_units": [32, 64], "lr": [1e-3], "seq_len": [seq_len]}
    lstm_best = simple_grid_search_and_train(
        X_train, y_train, X_val, y_val, model_type="lstm", search_space=lstm_search_space, epochs=30, batch_size=128, verbose=0
    )
    lstm_model = lstm_best["model"]
    print("Best LSTM config:", {"hidden": lstm_best["hidden"], "lr": lstm_best["lr"], "val_rmse": lstm_best["val_rmse"]})

    # Evaluate on test set
    lstm_preds = lstm_model.predict(X_test).ravel()
    # Remember we trained on scaled target; need to inverse-scale predictions
    # Our scaler scaled all columns together; to inverse only target y, we reconstruct arrays
    # Create dummy array to inverse transform only y
    dummy = np.zeros((len(lstm_preds), df.shape[1]))
    dummy[:, 0] = lstm_preds
    inv = scaler.inverse_transform(dummy)[:, 0]

    dummy_true = np.zeros((len(y_test.ravel()), df.shape[1]))
    dummy_true[:, 0] = y_test.ravel()
    inv_true = scaler.inverse_transform(dummy_true)[:, 0]

    lstm_metrics = {
        "rmse": rmse(inv_true, inv),
        "mae": mae(inv_true, inv),
        "mape": mape(inv_true, inv),
    }
    print("LSTM test metrics:", lstm_metrics)

    # 6) Train Transformer with simple grid search
    transformer_search_space = {"hidden_units": [32, 64], "lr": [1e-3], "seq_len": [seq_len]}
    transformer_best = simple_grid_search_and_train(
        X_train, y_train, X_val, y_val, model_type="transformer", search_space=transformer_search_space, epochs=30, batch_size=128, verbose=0
    )
    transformer_model = transformer_best["model"]
    print("Best Transformer config:", {"hidden": transformer_best["hidden"], "lr": transformer_best["lr"], "val_rmse": transformer_best["val_rmse"]})

    # Evaluate on test
    trans_preds = transformer_model.predict(X_test).ravel()
    dummy_t = np.zeros((len(trans_preds), df.shape[1]))
    dummy_t[:, 0] = trans_preds
    inv_t = scaler.inverse_transform(dummy_t)[:, 0]
    trans_metrics = {
        "rmse": rmse(inv_true, inv_t),
        "mae": mae(inv_true, inv_t),
        "mape": mape(inv_true, inv_t),
    }
    print("Transformer test metrics:", trans_metrics)

    # 7) Compare all metrics in dataframe
    results_df = pd.DataFrame({
        "model": ["SARIMAX", "LSTM", "Transformer"],
        "rmse": [sarimax_res["metrics"]["rmse"], lstm_metrics["rmse"], trans_metrics["rmse"]],
        "mae": [sarimax_res["metrics"]["mae"], lstm_metrics["mae"], trans_metrics["mae"]],
        "mape": [sarimax_res["metrics"]["mape"], lstm_metrics["mape"], trans_metrics["mape"]],
    })
    print("\nComparison:\n", results_df)

    # 8) Plot predictions vs actual for test window for the winning model by RMSE
    winner_idx = results_df["rmse"].argmin()
    winner = results_df.iloc[winner_idx]["model"]
    print(f"Best model by RMSE: {winner}")

    if winner == "SARIMAX":
        pred_series = sarimax_res["pred"].values
        actual_series = sarimax_res["y_test"].values
    elif winner == "LSTM":
        pred_series = inv
        actual_series = inv_true
    else:
        pred_series = inv_t
        actual_series = inv_true

    plt.figure(figsize=(12, 5))
    plt.plot(actual_series, label="Actual")
    plt.plot(pred_series, label="Predicted")
    plt.title(f"{winner} predictions vs actual (test window)")
    plt.legend()
    plt.tight_layout()
    plt.show()

    # 9) Explainability
    feature_names = df.columns.tolist()
    print("Running explainability...")

    # SHAP for LSTM
    try:
        if SHAP_AVAILABLE:
            df_imp, shap_values = explain_lstm_with_shap(lstm_model, X_test, feature_names)
        else:
            print("SHAP not installed. To enable SHAP explanations run: pip install shap")
    except Exception as e:
        print("SHAP explanation failed:", e)

    # Attention visualization for Transformer
    try:
        att_scores = plot_transformer_attention(transformer_model, X_test[:1])
        if att_scores is not None:
            print("Attention matrix shape:", att_scores.shape)
    except Exception as e:
        print("Transformer attention visualization failed:", e)

    # Save best models
    save_dir = "models_output"
    os.makedirs(save_dir, exist_ok=True)
    lstm_model.save(os.path.join(save_dir, "best_lstm.h5"))
    transformer_model.save(os.path.join(save_dir, "best_transformer.h5"))
    print(f"Saved models to {save_dir}")

    # Export results to CSV
    results_df.to_csv(os.path.join(save_dir, "model_comparison.csv"), index=False)
    print("Saved comparison CSV")

    print("Done.")


if __name__ == "__main__":
    main()